{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a8d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723631f",
   "metadata": {},
   "source": [
    "## core model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(input_features, input_shape = (512, 512, 3)):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=input_shape),\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(1024),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(input_features, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b658a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8948053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab16cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images path: d:\\college docs\\3rd_year_sem_5\\deep_learning\\PyTorch_CNN_Model\\archive\\images\\train\n",
      "Training labels path: d:\\college docs\\3rd_year_sem_5\\deep_learning\\PyTorch_CNN_Model\\archive\\labels\\train\n",
      "Image size: 224x224\n",
      "Batch size: 32\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "TRAIN_IMAGES_PATH = r\"d:\\college docs\\3rd_year_sem_5\\deep_learning\\PyTorch_CNN_Model\\archive\\images\\train\"\n",
    "VAL_IMAGES_PATH = r\"d:\\college docs\\3rd_year_sem_5\\deep_learning\\PyTorch_CNN_Model\\archive\\images\\val\"\n",
    "TRAIN_LABELS_PATH = r\"d:\\college docs\\3rd_year_sem_5\\deep_learning\\PyTorch_CNN_Model\\archive\\labels\\train\"\n",
    "VAL_LABELS_PATH = r\"d:\\college docs\\3rd_year_sem_5\\deep_learning\\PyTorch_CNN_Model\\archive\\labels\\val\"\n",
    "\n",
    "# Model parameters\n",
    "IMG_SIZE = 224  # Using smaller size for faster training\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2  # person vs no-person (binary classification)\n",
    "\n",
    "print(f\"Training images path: {TRAIN_IMAGES_PATH}\")\n",
    "print(f\"Training labels path: {TRAIN_LABELS_PATH}\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fed10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_yolo_data(images_path, labels_path, img_size=224):\n",
    "    \"\"\"\n",
    "    Load and preprocess YOLO format data for binary classification (person vs no-person)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    for i, image_file in enumerate(image_files):\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Processing image {i+1}/{len(image_files)}\")\n",
    "            \n",
    "        # Load image\n",
    "        image_path = os.path.join(images_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "            \n",
    "        # Resize image\n",
    "        image = cv2.resize(image, (img_size, img_size))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "        \n",
    "        # Load corresponding label\n",
    "        label_file = image_file.replace('.jpg', '.txt')\n",
    "        label_path = os.path.join(labels_path, label_file)\n",
    "        \n",
    "        # Check if person is present (class 0 in YOLO format)\n",
    "        has_person = 0\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    class_id = int(line.strip().split()[0])\n",
    "                    if class_id == 0:  # Person class\n",
    "                        has_person = 1\n",
    "                        break\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(has_person)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "print(\"Data loading function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ab7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Found 13754 images\n",
      "Processing image 1/13754\n",
      "Processing image 1001/13754\n",
      "Processing image 2001/13754\n",
      "Processing image 3001/13754\n",
      "Processing image 4001/13754\n",
      "Processing image 5001/13754\n",
      "Processing image 6001/13754\n",
      "Processing image 7001/13754\n",
      "Processing image 8001/13754\n",
      "Processing image 9001/13754\n",
      "Processing image 10001/13754\n",
      "Processing image 11001/13754\n",
      "Processing image 12001/13754\n",
      "Processing image 13001/13754\n",
      "\n",
      "Training data loaded:\n",
      "X_train shape: (13754, 224, 224, 3)\n",
      "y_train shape: (13754,)\n",
      "Positive samples (with person): 13754\n",
      "Negative samples (no person): 0\n",
      "\n",
      "Loading validation data...\n",
      "Found 4000 images\n",
      "Processing image 1/4000\n",
      "Processing image 1001/4000\n",
      "Processing image 2001/4000\n",
      "Processing image 3001/4000\n",
      "X_val shape: (4000, 224, 224, 3)\n",
      "y_val shape: (4000,)\n",
      "Validation positive samples: 4000\n",
      "Validation negative samples: 0\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "X_train, y_train = load_yolo_data(TRAIN_IMAGES_PATH, TRAIN_LABELS_PATH, IMG_SIZE)\n",
    "\n",
    "print(f\"\\nTraining data loaded:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"Positive samples (with person): {np.sum(y_train)}\")\n",
    "print(f\"Negative samples (no person): {len(y_train) - np.sum(y_train)}\")\n",
    "\n",
    "# Check if validation data exists\n",
    "if os.path.exists(VAL_IMAGES_PATH) and os.path.exists(VAL_LABELS_PATH):\n",
    "    print(\"\\nLoading validation data...\")\n",
    "    X_val, y_val = load_yolo_data(VAL_IMAGES_PATH, VAL_LABELS_PATH, IMG_SIZE)\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"y_val shape: {y_val.shape}\")\n",
    "    print(f\"Validation positive samples: {np.sum(y_val)}\")\n",
    "    print(f\"Validation negative samples: {len(y_val) - np.sum(y_val)}\")\n",
    "else:\n",
    "    # Split training data if no validation set exists\n",
    "    print(\"\\nNo validation set found. Splitting training data...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    print(f\"After split:\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"Training positive samples: {np.sum(y_train)}\")\n",
    "    print(f\"Validation positive samples: {np.sum(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf306c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample data\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    label = \"Person\" if y_train[i] == 1 else \"No Person\"\n",
    "    plt.title(f'{label}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check data distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(['No Person', 'Person'], counts)\n",
    "plt.title('Training Data Distribution')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class distribution: {dict(zip(unique, counts))}\")\n",
    "print(f\"Positive class ratio: {counts[1]/(counts[0]+counts[1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dae7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the CNN model for people detection (binary classification)\n",
    "def CNN_model_updated(input_shape=(224, 224, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    Updated CNN model optimized for people detection\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # First block\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=input_shape),\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        # Second block\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        # Third block\n",
    "        keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        # Fourth block\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        # Classifier\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        \n",
    "        # Output layer for binary classification\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Binary classification (person/no-person)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = CNN_model_updated(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5655f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',  # For binary classification\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2312444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for better generalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# No augmentation for validation data\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Prepare data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Callbacks for training\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        'best_people_detection_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Data augmentation and callbacks prepared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 50\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
    "    axes[1, 0].set_title('Model Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
    "    axes[1, 1].set_title('Model Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e18822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "val_loss, val_accuracy, val_precision, val_recall = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(\"Final Model Performance:\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "print(f\"Validation F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['No Person', 'Person'])\n",
    "plt.yticks(tick_marks, ['No Person', 'Person'])\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['No Person', 'Person']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def visualize_predictions(X, y_true, y_pred_proba, num_samples=12):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    indices = np.random.choice(len(X), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(3, 4, i+1)\n",
    "        plt.imshow(X[idx])\n",
    "        \n",
    "        true_label = \"Person\" if y_true[idx] == 1 else \"No Person\"\n",
    "        pred_proba = y_pred_proba[idx][0]\n",
    "        pred_label = \"Person\" if pred_proba > 0.5 else \"No Person\"\n",
    "        \n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        plt.title(f'True: {true_label}\\nPred: {pred_label} ({pred_proba:.3f})', \n",
    "                 color=color, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions on Validation Set', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show prediction examples\n",
    "visualize_predictions(X_val, y_val, y_pred_proba)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('people_detection_cnn_model.h5')\n",
    "print(\"\\nModel saved as 'people_detection_cnn_model.h5'\")\n",
    "\n",
    "# Save model architecture as JSON (optional)\n",
    "model_json = model.to_json()\n",
    "with open(\"people_detection_model_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Model architecture saved as 'people_detection_model_architecture.json'\")\n",
    "print(\"\\nTraining completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
