{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9c6c75",
   "metadata": {},
   "source": [
    "## prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af18ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# --- Constants ---\n",
    "ONNX_MODEL_PATH = 'object_detector_model_tf/person_detector_model.onnx'\n",
    "VIDEO_FILE_PATH = 'archive/ssvid.net--HUGE-Speech-Practice-Audience-with-Applause-5-minute-presentation_1080p.mp4'\n",
    "IMAGE_FILE_PATH = 'output_image.jpg'\n",
    "\n",
    "\n",
    "IMAGE_SIZE = (226, 226)  # Input image dimensions for the model\n",
    "GRID_SIZE = 7           # The image will be divided into a 7x7 grid\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Confidence threshold for displaying a bounding box\n",
    "NMS_IOU_THRESHOLD = 0.4     # IoU threshold for Non-Max Suppression\n",
    "CROWD_THRESHOLD = 4         # Number of people to trigger a crowd warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553be37",
   "metadata": {},
   "source": [
    "## detection mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89b2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(predictions, confidence_threshold, nms_iou_threshold):\n",
    "    \"\"\"\n",
    "    Decodes the model's raw output tensor into a list of final bounding boxes.\n",
    "    Applies confidence thresholding and Non-Max Suppression.\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "\n",
    "    cell_w = IMAGE_SIZE[1] / GRID_SIZE\n",
    "    cell_h = IMAGE_SIZE[0] / GRID_SIZE\n",
    "\n",
    "    # Iterate over each grid cell\n",
    "    for y in range(GRID_SIZE):\n",
    "        for x in range(GRID_SIZE):\n",
    "            cell_preds = predictions[y, x, :]\n",
    "            confidence = cell_preds[4]\n",
    "\n",
    "            if confidence >= confidence_threshold:\n",
    "                # Decode box coordinates\n",
    "                x_rel, y_rel, w_rel, h_rel = cell_preds[:4]\n",
    "\n",
    "                # Convert relative coordinates to absolute image coordinates\n",
    "                abs_x_center = (x * cell_w) + (x_rel * cell_w)\n",
    "                abs_y_center = (y * cell_h) + (y_rel * cell_h)\n",
    "                abs_w = w_rel * IMAGE_SIZE[1]\n",
    "                abs_h = h_rel * IMAGE_SIZE[0]\n",
    "\n",
    "                # Convert center coordinates to top-left coordinates for NMS\n",
    "                x1 = abs_x_center - (abs_w / 2)\n",
    "                y1 = abs_y_center - (abs_h / 2)\n",
    "                x2 = x1 + abs_w\n",
    "                y2 = y1 + abs_h\n",
    "\n",
    "                boxes.append([y1, x1, y2, x2]) # NMS expects [y1, x1, y2, x2]\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    if not boxes:\n",
    "        return [], []\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_iou_threshold)\n",
    "    \n",
    "    final_boxes = [boxes[i] for i in indices]\n",
    "    final_confidences = [confidences[i] for i in indices]\n",
    "\n",
    "    return final_boxes, final_confidences\n",
    "\n",
    "\n",
    "def draw_boxes_with_warning(image, boxes, confidences, crowd_threshold):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes on an image and displays a crowd warning if the\n",
    "    number of boxes exceeds the threshold.\n",
    "    \"\"\"\n",
    "    for box, conf in zip(boxes, confidences):\n",
    "        y1, x1, y2, x2 = [int(coord) for coord in box]\n",
    "        # Draw the rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        # Prepare the label text\n",
    "        label = f\"Person: {conf:.2f}\"\n",
    "        # Get text size to draw a background rectangle\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "        # Draw background and text\n",
    "        cv2.rectangle(image, (x1, y1 - h - 10), (x1 + w, y1), (0, 255, 0), -1)\n",
    "        cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "    # Display crowd warning\n",
    "    if len(boxes) > crowd_threshold:\n",
    "        warning_text = \"CROWD DETECTED!\"\n",
    "        (w, h), _ = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 1, 3)\n",
    "        cv2.rectangle(image, (10, 10), (10 + w + 10, 10 + h + 10), (0, 0, 255), -1)\n",
    "        cv2.putText(image, warning_text, (15, 15 + h), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 3)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49def3",
   "metadata": {},
   "source": [
    "## Video inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72baebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowd_monitoring_video(onnx_model_path, video_path, output_path='output_video_crowd.mp4'):\n",
    "    \"\"\"\n",
    "    Runs crowd monitoring on a video file using the ONNX model.\n",
    "    \"\"\"\n",
    "    print(f\"--- Running crowd monitoring on video: {video_path} ---\")\n",
    "    session = ort.InferenceSession(onnx_model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "        frame_input = frame_resized / 255.0\n",
    "        frame_input = np.expand_dims(frame_input, axis=0).astype(np.float32)\n",
    "\n",
    "        preds = session.run(None, {input_name: frame_input})[0][0]\n",
    "\n",
    "        boxes, confidences = decode_predictions(preds, CONFIDENCE_THRESHOLD, NMS_IOU_THRESHOLD)\n",
    "\n",
    "        final_boxes_scaled = []\n",
    "        for box in boxes:\n",
    "            y1, x1, y2, x2 = box\n",
    "            y1_s = y1 * (height / IMAGE_SIZE[0])\n",
    "            x1_s = x1 * (width / IMAGE_SIZE[1])\n",
    "            y2_s = y2 * (height / IMAGE_SIZE[0])\n",
    "            x2_s = x2 * (width / IMAGE_SIZE[1])\n",
    "            final_boxes_scaled.append([y1_s, x1_s, y2_s, x2_s])\n",
    "\n",
    "        output_frame = draw_boxes_with_warning(frame.copy(), final_boxes_scaled, confidences, CROWD_THRESHOLD)\n",
    "        out.write(output_frame)\n",
    "\n",
    "        # Display the resulting frame (optional, can be slow)\n",
    "        cv2.imshow('Crowd Monitoring - Press Q to Quit', output_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    print(f\"--- Video processing complete. Output video saved to '{output_path}' ---\")\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e5c61",
   "metadata": {},
   "source": [
    "## image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d266bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowd_monitoring_image(onnx_model_path, image_path, output_path='output_image_crowd.jpg'):\n",
    "    \"\"\"\n",
    "    Runs crowd monitoring on a single image using the ONNX model.\n",
    "    \"\"\"\n",
    "    print(f\"--- Running crowd monitoring on image: {image_path} ---\")\n",
    "    session = ort.InferenceSession(onnx_model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image.\")\n",
    "        return\n",
    "\n",
    "    original_h, original_w, _ = image.shape\n",
    "\n",
    "    # Preprocess image\n",
    "    image_resized = cv2.resize(image, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "    image_input = image_resized / 255.0\n",
    "    image_input = np.expand_dims(image_input, axis=0).astype(np.float32)\n",
    "\n",
    "    # Get predictions\n",
    "    preds = session.run(None, {input_name: image_input})[0][0]\n",
    "\n",
    "    # Decode predictions and draw boxes\n",
    "    boxes, confidences = decode_predictions(preds, CONFIDENCE_THRESHOLD, NMS_IOU_THRESHOLD)\n",
    "\n",
    "    # Scale boxes back to original image size\n",
    "    final_boxes_scaled = []\n",
    "    for box in boxes:\n",
    "        y1, x1, y2, x2 = box\n",
    "        y1_s = y1 * (original_h / IMAGE_SIZE[0])\n",
    "        x1_s = x1 * (original_w / IMAGE_SIZE[1])\n",
    "        y2_s = y2 * (original_h / IMAGE_SIZE[0])\n",
    "        x2_s = x2 * (original_w / IMAGE_SIZE[1])\n",
    "        final_boxes_scaled.append([y1_s, x1_s, y2_s, x2_s])\n",
    "\n",
    "    output_image = draw_boxes_with_warning(image.copy(), final_boxes_scaled, confidences, CROWD_THRESHOLD)\n",
    "\n",
    "    # Save the output\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "    print(f\"Found {len(final_boxes_scaled)} person(s). Output saved to '{output_path}'\")\n",
    "\n",
    "    # Display the output image (optional)\n",
    "    # cv2.imshow('Crowd Detections', output_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa02b9",
   "metadata": {},
   "source": [
    "## function calling for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9b83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running crowd monitoring on video: archive/ssvid.net--HUGE-Speech-Practice-Audience-with-Applause-5-minute-presentation_1080p.mp4 ---\n",
      "--- Video processing complete. Output video saved to 'output_video_crowd.mp4' ---\n"
     ]
    }
   ],
   "source": [
    "# --- Run on Video ---\n",
    "crowd_monitoring_video(ONNX_MODEL_PATH, VIDEO_FILE_PATH)\n",
    "\n",
    "# --- Run on Image ---\n",
    "#crowd_monitoring_image(ONNX_MODEL_PATH, IMAGE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc77a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcnn (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
